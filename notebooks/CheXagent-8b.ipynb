{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd0a5f2-d2de-41e0-a624-f98661c7a82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/users/restrepoda/.conda/envs/base_ml/lib/python3.12/site-packages/transformers/utils/hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "A new version of the following files was downloaded from https://huggingface.co/StanfordAIMI/CheXagent-8b:\n",
      "- processing_chexagent.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/StanfordAIMI/CheXagent-8b:\n",
      "- configuration_chexagent.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/StanfordAIMI/CheXagent-8b:\n",
      "- modeling_chexagent.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f535e600c9d0454ebe1030cd1821c18b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import io\n",
    "\n",
    "import requests\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoModelForCausalLM, AutoProcessor, GenerationConfig\n",
    "\n",
    "# step 1: Setup constant\n",
    "device = \"cuda\"\n",
    "dtype = torch.float16\n",
    "\n",
    "# step 2: Load Processor and Model\n",
    "processor = AutoProcessor.from_pretrained(\"StanfordAIMI/CheXagent-8b\", trust_remote_code=True, output_attentions=True,\n",
    "        output_scores=True,\n",
    "        return_dict_in_generate=True)\n",
    "generation_config = GenerationConfig.from_pretrained(\"StanfordAIMI/CheXagent-8b\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"StanfordAIMI/CheXagent-8b\", torch_dtype=dtype, trust_remote_code=True).to(device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8d9a1a-fab1-4656-aa49-21ca7245e0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9424105-a956-4d9b-9d39-d983a7d074cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerationConfig {\n",
       "  \"bos_token_id\": 1,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"max_length\": 512,\n",
       "  \"num_beams\": 5\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3bfdde1-9f13-438d-a083-d6538e9ee3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Both `max_new_tokens` (=512) and `max_length`(=512) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A right-sided pigtail catheter has been placed. There is no evidence of pneumothorax. The lungs are clear. The cardiomediastinal silhouette is within normal limits. No acute osseous abnormalities.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 3: Fetch the images\n",
    "image_path = \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Pleural_effusion-Metastatic_breast_carcinoma_Case_166_%285477628658%29.jpg\"\n",
    "#images = [Image.open(io.BytesIO(requests.get(image_path).content)).convert(\"RGB\")]\n",
    "images = [Image.open('/gpfs/workdir/restrepoda/datasets/MIMIC/mimic/preproc_224x224/s53890711_7d9bf1c6-fd83ac96-aff4a21e-bef0f1a6-c35f5c60.jpg').convert(\"RGB\")]\n",
    "\n",
    "# step 4: Generate the Findings section\n",
    "prompt = f'Describe the image'\n",
    "inputs = processor(images=images, text=f\" USER: <s>{prompt} ASSISTANT: <s>\", return_tensors=\"pt\").to(device=device, dtype=dtype)\n",
    "output = model.generate(**inputs,\n",
    "                bos_token_id=1,\n",
    "                eos_token_id=2,\n",
    "                max_length=512,\n",
    "                num_beams=5,\n",
    "\n",
    "                max_new_tokens=512,\n",
    "                do_sample=False,\n",
    "                temperature=0.01,\n",
    "                output_attentions=True,\n",
    "                output_scores=True,\n",
    "                return_dict_in_generate=True)\n",
    "\n",
    "response = processor.tokenizer.decode(output.sequences[0], skip_special_tokens=True)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8664fe1d-e156-4fba-a20d-dc5cd1f3194e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['sequences', 'sequences_scores', 'scores', 'beam_indices', 'attentions', 'past_key_values'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fcda91-4378-4677-a6ac-7db8bbfeac9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
